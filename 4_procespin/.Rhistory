support = list(set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE))
print(ps)
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F", pdf = pdf, parameters = ps, support = support,
type = type)
U$traits
u$pdf[1.4]
U$pdf[1.4]
U$pdf(1.4)
draws <- U$new(size = 100)
U$rand(10)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
U$pdf(1.4)
n <- U$new()
summary(U)
16/9
37/162
?U
?Distribution
U$rand(10)
library(distr6)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x <= middle] = 2/3
pdf[x > middle & x <= upper] = -2/3*(x-3)
return(pdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
U$rand(20,TRUE)
a <- U$rand(20,TRUE)
a
b <- Binomial$new()
b$rand(10)
U$rand(1)
cdf <- function(x){
cdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
upper <- self$getParameterValue("upper")
cdf[x >= upper] = 1
cdf[x >= lower & x < upper] = (x - lower) / (upper - lower)
return(cdf)
}
U <- Distribution$new(name = "Uniform", short_name = "unif", type = set6::Reals$new(),
support = set6::Interval$new(1, 10),  symmetric = TRUE, pdf = pdf, cdf = cdf, parameters = ps, description = "Custom uniform distribution")
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$mean()
#> Results from numeric calculations are approximate only. Better results may be available.
#> [1] 5.5
U$variance()
#> Results from numeric calculations are approximate only. Better results may be available.
#> [1] 6.75
U$hazard(5)
#> [1] 0.25
U$rand(5)
#> [1] 0.25
U$rand(5)
cdf <- function(x){
cdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
upper <- self$getParameterValue("upper")
cdf[x >= upper] = 1
cdf[x >= lower & x < upper] = (x - lower) / (upper - lower)
return(cdf)
}
U <- Distribution$new(name = "Uniform", short_name = "unif", type = set6::Reals$new(),
support = set6::Interval$new(1, 10),  symmetric = TRUE, pdf = pdf, cdf = cdf, parameters = ps, description = "Custom uniform distribution")
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
install.packages("pracma")
install.packages("GoFKernel")
library(distr6)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x <= middle] = 2/3
pdf[x > middle & x <= upper] = -2/3*(x-3)
return(pdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
U$rand(20)
sample_mean <- mean(a)
a <- U$rand(100)
sample_mean <- mean(a)
sample_mean
library(distr6)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x <= middle] = 2/3
pdf[x > middle & x <= upper] = -2/3*(x-3)
return(pdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
a <- U$rand(100000)
sample_mean <- mean(a)
sample_mean
library(distr6)
set.seed(42)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x <= middle] = 2/3
pdf[x >= middle & x <= upper] = -2/3*(x-3)
return(pdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE))
library(distr6)
set.seed(42)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x <= middle] = 2/3
pdf[x >= middle & x <= upper] = -2/3*(x-3)
return(pdf)
}
cdf <- function(x){
cdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
cdf[x>= upper] = 1
cdf[x >= middle & x < upper] =-1/3*x*x+2*x-2
cdf[x >= lower & x < middle] = 2/3*x-2/3
return(cdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
cdf = cdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
a <- U$rand(100000)
sample_mean <- mean(a)
sample_mean
library(distr6)
set.seed(42)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x <= middle] = 2/3
pdf[x > middle & x <= upper] = -2/3*(x-3)
return(pdf)
}
cdf <- function(x){
cdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
cdf[x>= upper] = 1
cdf[x >= middle & x < upper] =-1/3*x*x+2*x-2
cdf[x >= lower & x < middle] = 2/3*x-2/3
return(cdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
cdf = cdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
a <- U$rand(100000)
library(distr6)
set.seed(42)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x < middle] = 2/3
pdf[x >= middle & x < upper] = -2/3*(x-3)
return(pdf)
}
cdf <- function(x){
cdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
cdf[x>= upper] = 1
cdf[x >= middle & x < upper] =-1/3*x*x+2*x-2
cdf[x >= lower & x < middle] = 2/3*x-2/3
return(cdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
cdf = cdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
a <- U$rand(100000)
sample_mean <- mean(a)
sample_mean
library(distr6)
set.seed(42)
pdf <- function(x){
pdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
pdf[x >= lower & x < middle] = 2/3
pdf[x >= middle & x < upper] = -2/3*(x-3)
return(pdf)
}
cdf <- function(x){
cdf <- numeric(length(x))
lower <- self$getParameterValue("lower")
middle <- self$getParameterValue("middle")
upper <- self$getParameterValue("upper")
cdf[x>= upper] = 1
cdf[x >= middle & x < upper] =-1/3*x*x+2*x-2
cdf[x >= lower & x < middle] = 2/3*x-2/3
return(cdf)
}
ps <- ParameterSet$new(id = list("lower","middle", "upper"), value = c(1,2,3),
support = list(set6::Reals$new(),set6::Reals$new(),set6::Reals$new()),
settable = list(TRUE, TRUE, TRUE))
print(ps)
support <- set6::Interval$new(1, 3)
type <- set6::Reals$new()
U <- Distribution$new(name = "F",
pdf = pdf,
cdf = cdf,
parameters = ps,
support = support,
type = type)
decorate(U, c("CoreStatistics", "ExoticStatistics", "FunctionImputation"))
U$traits
summary(U)
sample_mean <- mean(U$rand(100))
sample_mean
sample_mean <- mean(U$rand(10))
sample_mean
sample_mean <- mean(U$rand(10000000))
sample_mean
library(shiny); runApp('Programming/R_markdowns_shiny-apps/3_french_population/3_french_population.R')
runApp('Programming/R_markdowns_shiny-apps/3_french_population/3_french_population.R')
library(tidyverse)
library(lmtest) # https://www.rdocumentation.org/packages/lmtest/versions/0.9-38
library(olsrr) # https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
data <- read.csv("procespin.txt", sep="\t")
ncol(data) #11 columns: y and 10 explanatory variables x1, ..., x10
nrow(data) #33 rows: data points
library(tidyverse)
library(lmtest) # https://www.rdocumentation.org/packages/lmtest/versions/0.9-38
library(olsrr) # https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
data <- read.csv("procespin.txt", sep="\t")
setwd("~/Programming/R_markdowns_shiny-apps/5_procespin")
library(tidyverse)
library(lmtest) # https://www.rdocumentation.org/packages/lmtest/versions/0.9-38
library(olsrr) # https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
data <- read.csv("procespin.txt", sep="\t")
ncol(data) #11 columns: y and 10 explanatory variables x1, ..., x10
nrow(data) #33 rows: data points
summary(data)
# We create the response variable ln(y) and plot the result
data$lny <- log(data$y)
plot(data$y, data$lny)
### Model implementation
simple_model = lm(lny ~ ., data = data %>% select(-y))
summary(simple_model)
plot(simple_model)
# helping source:
#   - https://boostedml.com/2019/03/linear-regression-plots-how-to-read-a-qq-plot.html
#
# Scale Location: It displays the fitted values of a regresison model along the
# x-axis and the square roote of the standardized residuals along the y-axis.
# it helps verify the homoscedasticity of the dataset for a given regression.
# Since the drawn pattern fails to be somewhat horizontal, showing instead a
# vaguely sinusoidal look, we can say that the spread of the residuals
# is unequal for the fitted value.
# Checking the model's homosedasticity with the Breusch-Pagan test
bptest(simple_model)
### Model implementation
reduced_model = lm(lny ~ ., data = data %>% select(c(lny, x1, x2, x4, x5)))
summary(reduced_model)
plot(reduced_model)
all_models <- lm(lny ~ ., data = data %>% select(-y))
### ------ /!\ WARNING: this might take a minute ------
all_models_results <- ols_step_best_subset(all_models)
### ---------------------------------------------------
plot(all_models_results)
plot(simple_model)
library(car)
durbinWatsonTest(model)
library(tidyverse)
library(lmtest) # https://www.rdocumentation.org/packages/lmtest/versions/0.9-38
library(olsrr) # https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
library(car)
data <- read.csv("procespin.txt", sep="\t")
ncol(data) #11 columns: y and 10 explanatory variables x1, ..., x10
nrow(data) #33 rows: data points
summary(data)
# We create the response variable ln(y) and plot the result
data$lny <- log(data$y)
plot(data$y, data$lny)
### Model implementation
simple_model = lm(lny ~ ., data = data %>% select(-y))
summary(simple_model)
plot(simple_model)
# x-axis and the square roote of the standardized residuals along the y-axis.
# it helps verify the homoscedasticity of the dataset for a given regression.
# Since the drawn pattern fails to be somewhat horizontal, showing instead a
# vaguely sinusoidal look, we can say that the spread of the residuals
# is unequal for the fitted value.
# Checking the model's homosedasticity with the Breusch-Pagan test
bptest(simple_model)
# Independence of residuals' error terms
# One of the main assumptions in linear regression is that there is no
# correlation between consecutive residuals. In other words, it’s assumed
# that the residuals are independent.
# When this assumption is violated, the standard errors of the coefficients in
# a regression model are likely to be underestimated which means predictor
# variables are more likely to be deemed statistically significant when they’re
# actually not.
# One way to determine if this assumption is met is to perform a Durbin-Watson
# test
durbinWatsonTest(simple_model)
data
library(tidyverse)
library(lmtest) # https://www.rdocumentation.org/packages/lmtest/versions/0.9-38
library(olsrr) # https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
library(car)
data <- read.csv("procespin.txt", sep="\t")
ncol(data) #11 columns: y and 10 explanatory variables x1, ..., x10
nrow(data) #33 rows: data points
summary(data)
# We create the response variable ln(y) and plot the result
data$lny <- log(data$y)
plot(data$y, data$lny)
### Model implementation
simple_model = lm(lny ~ ., data = data %>% select(-y))
summary(simple_model)
plot(simple_model)
# x-axis and the square roote of the standardized residuals along the y-axis.
# it helps verify the homoscedasticity of the dataset for a given regression.
# Since the drawn pattern fails to be somewhat horizontal, showing instead a
# vaguely sinusoidal look, we can say that the spread of the residuals
# is unequal for the fitted value.
# Checking the model's homosedasticity with the Breusch-Pagan test
bptest(simple_model)
#
# Independence of residuals' error terms: One of the main assumptions in linear
# regression is that there is no correlation between consecutive residuals.
# In other words, it’s assumed that the residuals are independent.
# When this assumption is violated, the standard errors of the coefficients in
# a regression model are likely to be underestimated which means predictor
# variables are more likely to be deemed statistically significant when they’re
# actually not.
# One way to determine if this assumption is met is to perform a Durbin-Watson
# test
durbinWatsonTest(simple_model)
### Model implementation
reduced_model = lm(lny ~ ., data = data %>% select(c(lny, x1, x2, x4, x5)))
summary(reduced_model)
plot(reduced_model)
plot(all_models_results)
### Observations
### Model implementation
reduced_model = lm(lny ~ ., data = data %>% select(c(lny, x1, x2, x4, x5)))
summary(reduced_model)
plot(reduced_model)
plot(all_models_results)
all_models <- lm(lny ~ ., data = data %>% select(-y))
### ------ /!\ WARNING: this might take a minute ------
all_models_results <- ols_step_best_subset(all_models)
### ---------------------------------------------------
plot(all_models_results)
n=100
p=10
p0=5
sigma=1
beta0=c(rep(5,p0), rep(0,p-p0))
x=sapply(1:p,FUN=function(x){rnorm(n,0,1)})
y=x%*%beta0+rnorm(n,0,1)
plot(y,x%*%beta0)
bols = solve((t(x)%*%x))%*%t(x)%*%y
#install.packages("glmnet")
library(glmnet)
fitr=glmnet(x,y,alpha=0) #ridge
fitl=glmnet(x,y,alpha=1) #lasso
coef(fitr)
coef(fitl)
simple_model
summary(simple_model)$fstatistic
library(tidyverse)
library(lmtest) # https://www.rdocumentation.org/packages/lmtest/versions/0.9-38
library(olsrr) # https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
library(car)
data <- read.csv("procespin.txt", sep="\t")
ncol(data) #11 columns: y and 10 explanatory variables x1, ..., x10
nrow(data) #33 rows: data points
summary(data)
# We create the response variable ln(y) and plot the result
data$lny <- log(data$y)
plot(data$y, data$lny)
u
plot(simple_model)
# helping source:
#   - https://boostedml.com/2019/03/linear-regression-plots-how-to-read-a-qq-plot.html
#
# Scale Location: It displays the fitted values of a regresison model along the
# x-axis and the square roote of the standardized residuals along the y-axis.
# it helps verify the homoscedasticity of the dataset for a given regression.
# Since the drawn pattern fails to be somewhat horizontal, showing instead a
# vaguely sinusoidal look, we can say that the spread of the residuals
# is unequal for the fitted value.
# Checking the model's homosedasticity with the Breusch-Pagan test
bptest(simple_model)
#
# Independence of residuals' error terms: One of the main assumptions in linear
# regression is that there is no correlation between consecutive residuals.
# In other words, it’s assumed that the residuals are independent.
# When this assumption is violated, the standard errors of the coefficients in
# a regression model are likely to be underestimated which means predictor
# variables are more likely to be deemed statistically significant when they’re
# actually not.
# One way to determine if this assumption is met is to perform a Durbin-Watson
# test
durbinWatsonTest(simple_model)
### Model implementation
reduced_model = lm(lny ~ ., data = data %>% select(c(lny, x1, x2, x4, x5)))
summary(reduced_model)
plot(reduced_model)
all_models <- lm(lny ~ ., data = data %>% select(-y))
### ------ /!\ WARNING: this might take a minute ------
all_models_results <- ols_step_best_subset(all_models)
### ---------------------------------------------------
plot(all_models_results)
summary(all_models_results)
all_models_results
